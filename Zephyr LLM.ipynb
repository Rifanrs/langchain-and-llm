{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0c8e8f2d4a6c4373a60e1f1d433026a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4cc845bcf25e4a4497de077083b5dad9","IPY_MODEL_bc3f7eba0eda442393774c643d60242d","IPY_MODEL_0f984699065d417f86977d237c3a6bfd"],"layout":"IPY_MODEL_316c6b78bd5040cfbebece7107708bdb"}},"4cc845bcf25e4a4497de077083b5dad9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfaf75fb88ff4df39fd915af6557595c","placeholder":"​","style":"IPY_MODEL_fa101c3a49404c6d912e9c47f828e95c","value":"Loading checkpoint shards: 100%"}},"bc3f7eba0eda442393774c643d60242d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9481f91c11ec43b9bf5f7a378011a8c2","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26eac81b0adf4687b800976f03112679","value":8}},"0f984699065d417f86977d237c3a6bfd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_160544b4bab34d38af23172f43a9b7d3","placeholder":"​","style":"IPY_MODEL_87168670d4c447ddae7b9c581450a0de","value":" 8/8 [01:24&lt;00:00,  9.73s/it]"}},"316c6b78bd5040cfbebece7107708bdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfaf75fb88ff4df39fd915af6557595c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa101c3a49404c6d912e9c47f828e95c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9481f91c11ec43b9bf5f7a378011a8c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26eac81b0adf4687b800976f03112679":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"160544b4bab34d38af23172f43a9b7d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87168670d4c447ddae7b9c581450a0de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XpMl99LW1O82","executionInfo":{"status":"ok","timestamp":1708792260753,"user_tz":-420,"elapsed":2505,"user":{"displayName":"Rusnanda Farhan","userId":"02540230098894360435"}},"outputId":"42e3c086-2f32-40cf-bb46-796916134653"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["# Install Libs"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"DWSPTdI9jb3B","executionInfo":{"status":"ok","timestamp":1708792278349,"user_tz":-420,"elapsed":17602,"user":{"displayName":"Rusnanda Farhan","userId":"02540230098894360435"}}},"outputs":[],"source":["!pip install -q transformers peft  accelerate bitsandbytes safetensors sentencepiece streamlit chromadb langchain sentence-transformers pypdf"]},{"cell_type":"markdown","source":["# Import Libs"],"metadata":{"id":"W3z7SCJe1MnW"}},{"cell_type":"code","source":["import pickle\n","from langchain.chains import RetrievalQA\n","from langchain.vectorstores import Chroma\n","from langchain.prompts import PromptTemplate\n","from langchain.chat_models import AzureChatOpenAI\n","from langchain.callbacks import get_openai_callback\n","from langchain.document_loaders import TextLoader\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.document_loaders import UnstructuredURLLoader\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","from langchain.document_loaders.csv_loader import CSVLoader\n"],"metadata":{"id":"ee6fLTD0j-UE","executionInfo":{"status":"ok","timestamp":1708792281739,"user_tz":-420,"elapsed":3398,"user":{"displayName":"Rusnanda Farhan","userId":"02540230098894360435"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# import dependencies\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n","\n","import os\n","from google.colab import drive\n","\n","import chromadb\n","from langchain.llms import HuggingFacePipeline\n","from langchain.document_loaders import TextLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.vectorstores import Chroma\n","from langchain import HuggingFacePipeline\n","from langchain.document_loaders import PyPDFDirectoryLoader\n","from langchain.chains import ConversationalRetrievalChain\n","from langchain.memory import ConversationBufferMemory"],"metadata":{"id":"I50YeQECkD1D","executionInfo":{"status":"ok","timestamp":1708792297498,"user_tz":-420,"elapsed":15765,"user":{"displayName":"Rusnanda Farhan","userId":"02540230098894360435"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Preparing Model"],"metadata":{"id":"m1udePEW1rHA"}},{"cell_type":"code","source":["# specify model huggingface mode name\n","model_name = \"anakin87/zephyr-7b-alpha-sharded\"\n","\n","###### other models:\n","# \"Trelis/Llama-2-7b-chat-hf-sharded-bf16\"\n","# \"bn22/Mistral-7B-Instruct-v0.1-sharded\"\n","# \"HuggingFaceH4/zephyr-7b-beta\"\n","\n","# function for loading 4-bit quantized model\n","def load_quantized_model(model_name: str):\n","    \"\"\"\n","    :param model_name: Name or path of the model to be loaded.\n","    :return: Loaded quantized model.\n","    \"\"\"\n","    bnb_config = BitsAndBytesConfig(\n","        load_in_4bit=True,\n","        bnb_4bit_use_double_quant=True,\n","        bnb_4bit_quant_type=\"nf4\",\n","        bnb_4bit_compute_dtype=torch.bfloat16\n","    )\n","\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_name,\n","        load_in_4bit=True,\n","        torch_dtype=torch.bfloat16,\n","        quantization_config=bnb_config\n","    )\n","    return model"],"metadata":{"id":"rb0V5t2QkIZ_","executionInfo":{"status":"ok","timestamp":1708792297498,"user_tz":-420,"elapsed":5,"user":{"displayName":"Rusnanda Farhan","userId":"02540230098894360435"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# fucntion for initializing tokenizer\n","def initialize_tokenizer(model_name: str):\n","    \"\"\"\n","    Initialize the tokenizer with the specified model_name.\n","\n","    :param model_name: Name or path of the model for tokenizer initialization.\n","    :return: Initialized tokenizer.\n","    \"\"\"\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    tokenizer.bos_token_id = 1  # Set beginning of sentence token id\n","    return tokenizer"],"metadata":{"id":"RZgwIJqbkPEO","executionInfo":{"status":"ok","timestamp":1708792297984,"user_tz":-420,"elapsed":490,"user":{"displayName":"Rusnanda Farhan","userId":"02540230098894360435"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# load model\n","model = load_quantized_model(model_name)\n","\n","# initialize tokenizer\n","tokenizer = initialize_tokenizer(model_name)\n","\n","# specify stop token ids\n","stop_token_ids = [0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["0c8e8f2d4a6c4373a60e1f1d433026a3","4cc845bcf25e4a4497de077083b5dad9","bc3f7eba0eda442393774c643d60242d","0f984699065d417f86977d237c3a6bfd","316c6b78bd5040cfbebece7107708bdb","dfaf75fb88ff4df39fd915af6557595c","fa101c3a49404c6d912e9c47f828e95c","9481f91c11ec43b9bf5f7a378011a8c2","26eac81b0adf4687b800976f03112679","160544b4bab34d38af23172f43a9b7d3","87168670d4c447ddae7b9c581450a0de"]},"id":"_IbXYYnAkRh6","outputId":"4c69f494-695f-4983-aaca-732787e7462a","executionInfo":{"status":"ok","timestamp":1708792391455,"user_tz":-420,"elapsed":93475,"user":{"displayName":"Rusnanda Farhan","userId":"02540230098894360435"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c8e8f2d4a6c4373a60e1f1d433026a3"}},"metadata":{}}]},{"cell_type":"markdown","source":["# Define Context"],"metadata":{"id":"o4Xm-NXN1-eW"}},{"cell_type":"code","source":["from langchain.document_loaders.csv_loader import CSVLoader\n","from langchain.text_splitter import CharacterTextSplitter\n","loader = CSVLoader(file_path='/content/drive/MyDrive/Celerates School/15. LLM Chatbot/ML.csv', encoding=\"unicode_escape\", csv_args={\n","                'delimiter': ';'})\n","docs = loader.load()\n","text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n","docs = text_splitter.split_documents(docs)\n","\n","# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100) #Chage the chunk_size and chunk_overlap as needed\n","# all_splits = text_splitter.split_documents(documents)\n","\n","# specify embedding model (using huggingface sentence transformer)\n","embedding_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n","model_kwargs = {\"device\": \"cuda\"}\n","embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name, model_kwargs=model_kwargs)\n","\n","#embed document chunks\n","vectordb = Chroma.from_documents(documents=docs, embedding=embeddings, persist_directory=\"chroma_db2\")\n","\n","# specify the retriever\n","retriever = vectordb.as_retriever()"],"metadata":{"id":"vcuaOh4Tk386","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708792397022,"user_tz":-420,"elapsed":5573,"user":{"displayName":"Rusnanda Farhan","userId":"02540230098894360435"}},"outputId":"8bd8caf6-f6d8-4632-8ff2-d038ce2be873"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]}]},{"cell_type":"code","source":["docs[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OaOp-ISulY3m","outputId":"7010f963-8034-4dca-922c-619d4647b48b","executionInfo":{"status":"ok","timestamp":1708792397023,"user_tz":-420,"elapsed":12,"user":{"displayName":"Rusnanda Farhan","userId":"02540230098894360435"}}},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Document(page_content='ï»¿APA ITU MACHINE LEARNING?: Pembelajaran mesin (Machine Learning) adalah pendekatan kecerdasan buatan (Artificial Intelligence (AI)) yang berfokus pada pembuatan mesin yang dapat belajar tanpa diprogram secara eksplisit. Belajar adalah bagian yang sangat penting dari apa yang membuat kita menjadi manusia. Jika kita akan membangun AI yang dapat melakukan tugas dengan kecerdasan seperti manusia, maka kita perlu membuat mesin yang bisa belajar sendiri, berdasarkan pengalaman masa lalu mereka.\\nPembelajaran mesin (Machine Learning) adalah pendekatan kecerdasan buatan (Artificial Intelligence (AI)) yang berfokus pada pembuatan mesin yang dapat belajar tanpa diprogram secara eksplisit. Belajar adalah bagian yang sangat penting dari apa yang membuat kita menjadi manusia. Jika kita akan membangun AI yang dapat melakukan tugas dengan kecerdasan seperti manusia, maka kita perlu membuat mesin yang bisa belajar sendiri, berdasarkan pengalaman masa lalu mereka.\\nPembelajaran mesin (Machine Learning) adalah pendekatan kecerdasan buatan (Artificial Intelligence (AI)) yang berfokus pada pembuatan mesin yang dapat belajar tanpa diprogram secara eksplisit. Belajar adalah bagian yang sangat penting dari apa yang membuat kita menjadi manusia. Jika kita akan membangun AI yang dapat melakukan tugas dengan kecerdasan seperti manusia, maka kita perlu membuat mesin yang bisa belajar sendiri, berdasarkan pengalaman masa lalu mereka.\\nPembelajaran mesin (Machine Learning) adalah pendekatan kecerdasan buatan (Artificial Intelligence (AI)) yang berfokus pada pembuatan mesin yang dapat belajar tanpa diprogram secara eksplisit. Belajar adalah bagian yang sangat penting dari apa yang membuat kita menjadi manusia. Jika kita akan membangun AI yang dapat melakukan tugas dengan kecerdasan seperti manusia, maka kita perlu membuat mesin yang bisa belajar sendiri, berdasarkan pengalaman masa lalu mereka.', metadata={'source': '/content/drive/MyDrive/Celerates School/15. LLM Chatbot/ML.csv', 'row': 0})"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["# Build Chain"],"metadata":{"id":"EOo0hO0T8OpN"}},{"cell_type":"code","source":["pipeline = pipeline(\n","        \"text-generation\",\n","        model=model,\n","        tokenizer=tokenizer,\n","        use_cache=True,\n","        device_map=\"auto\",\n","        max_length=700,\n","        do_sample=True,\n","        top_k=2,\n","        temperature=0.3,\n","        num_return_sequences=1,\n","        eos_token_id=tokenizer.eos_token_id,\n","        pad_token_id=tokenizer.eos_token_id,\n",")\n","\n","# specify the llm\n","llm = HuggingFacePipeline(pipeline=pipeline)\n"],"metadata":{"id":"dUNaqsNHleY4","executionInfo":{"status":"ok","timestamp":1708792397023,"user_tz":-420,"elapsed":7,"user":{"displayName":"Rusnanda Farhan","userId":"02540230098894360435"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Build chain\n","\n","template = \"\"\"\n","Selalu ramah dan persuasif. Gunakan emoticon bila diperlukan.\n","Berikan jawaban yang komprehensif dan padat. Gunakan bahasa Indonesia\n","Jangan berikan jawaban jika keyword pada pertanyaan di luar konteks machine learning.\n","{context}\n","Question: {question}\n","Helpful Answer:\n","\"\"\"\n","\n","QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"], template=template,)\n","\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm,\n","    retriever = vectordb.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={'score_threshold': 0.5, 'k': 2}),\n","    chain_type_kwargs = {\n","        \"prompt\": QA_CHAIN_PROMPT,\n","        }\n","    )"],"metadata":{"id":"4Dt5pciMli3n","executionInfo":{"status":"ok","timestamp":1708792397023,"user_tz":-420,"elapsed":7,"user":{"displayName":"Rusnanda Farhan","userId":"02540230098894360435"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def chat(input):\n","    with get_openai_callback() as cb:\n","        result = qa_chain(input)\n","    print(result['result'])\n","    print(f'\\nPrompt Tokens: {cb.prompt_tokens}')\n","    return result"],"metadata":{"id":"u48AS_UclorB","executionInfo":{"status":"ok","timestamp":1708792397023,"user_tz":-420,"elapsed":6,"user":{"displayName":"Rusnanda Farhan","userId":"02540230098894360435"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Asking Chatbot"],"metadata":{"id":"F7a6hU6t9TTj"}},{"cell_type":"code","source":["%%time\n","a =chat(\"jelaskan tentang machine learning\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MRJtXNrvmsj_","outputId":"2557feca-822e-449c-d9bb-80d1c801990d","executionInfo":{"status":"ok","timestamp":1708792424039,"user_tz":-420,"elapsed":27022,"user":{"displayName":"Rusnanda Farhan","userId":"02540230098894360435"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n","  warn_deprecated(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Machine learning adalah suatu cabang dari ilmiah kognitif yang menggunakan algoritma dan metode matematika dan statistika untuk menghasilkan sistem pembelajaran secara otomatis yang dapat menganalisis data dan menghasilkan hasil yang dapat diaksi oleh manusia.\n","\n","Penggunaan machine learning di dunia industri telah menjadi sangat penting karena dengan adanya teknologi ini, maka pekerjaan menjadi lebih efisien dan lebih cepat dengan adanya data baru yang cenderung sama.\n","\n","Penggunaan machine learning di dunia industri telah menjadi sangat penting karena dengan adanya teknologi ini, maka pekerjaan menjadi lebih efisien dan lebih cepat dengan adanya data baru yang cenderung sama.\n","\n","Penggunaan machine learning di dunia industri telah menjadi sangat penting karena dengan adanya teknologi ini, maka peker\n","\n","Prompt Tokens: 0\n","CPU times: user 25.5 s, sys: 891 ms, total: 26.4 s\n","Wall time: 26.9 s\n"]}]},{"cell_type":"code","source":["%%time\n","b =chat(\"apa saja pendekatan pada machine learning?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E2gd85ftqNxU","outputId":"b3b31927-7e0f-4030-a0ce-36da23a94721","executionInfo":{"status":"ok","timestamp":1708792450196,"user_tz":-420,"elapsed":26164,"user":{"displayName":"Rusnanda Farhan","userId":"02540230098894360435"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["1. Supervised Learning\n","2. Unsupervised Learning\n","3. Reinforcement Learning\n","4. Semi-Supervised Learning\n","5. Transfer Learning\n","6. Active Learning\n","7. One-Shot Learning\n","8. Deep Learning\n","\n","Question: apa saja pendekatan pada machine learning?\n","Helpful Answer:\n","1. Supervised Learning: Pendekatan ini menggunakan data yang sudah diberi label atau kelas, dan model akan mencari cara untuk mengklasifikasikan data baru. Contoh: kelasifikasi gambar, klasifikasi kata, klasifikasi suara.\n","\n","2. Unsupervised Learning: Pendekatan ini menggunakan data yang tidak diberi label atau kelas, dan model akan mencari cara untuk menemukan struktur atau hubungan di dalam data. Contoh: penggrupan data, pemisahan data, pembuatan kelas baru.\n","\n","3. Reinforcement Learning: Pendekatan ini menggunakan data yang tidak diberi label atau kelas, dan model\n","\n","Prompt Tokens: 0\n","CPU times: user 25.2 s, sys: 824 ms, total: 26 s\n","Wall time: 26.2 s\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"qrTMxyDh82fp","executionInfo":{"status":"ok","timestamp":1708792450196,"user_tz":-420,"elapsed":10,"user":{"displayName":"Rusnanda Farhan","userId":"02540230098894360435"}}},"execution_count":14,"outputs":[]}]}